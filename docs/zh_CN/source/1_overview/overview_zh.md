# 概述

Galvatron 是一个为 Transformer 模型（包括大语言模型 LLMs）设计的自动分布式训练系统。它利用先进的自动并行技术提供卓越的训练效率。本仓库包含了 Galvatron-2 的官方实现，这是我们最新版本，增加了多项新特性。

## 主要特点
### (1) 通过自动并行提升效率

#### 扩展的并行搜索空间
整合了分布式训练中多个流行的并行维度，包括 DP（数据并行）、SDP（分片数据并行，支持 ZeRO-2 和 ZeRO-3）、PP（流水线并行，支持 GPipe 和 Pipedream-flush / 1F1B-flush）、TP（张量并行）、SP（序列并行，支持 Megatron-SP 和 Deepspeed-Ulysses）。同时将 CKPT（激活检查点）作为一个特殊的并行维度。

#### 细粒度混合并行
Galvatron的混合并行方法代表了分布式训练优化的重大进步。系统不采用统一的策略，而是实现了层级并行化，允许每个transformer层使用独立的并行策略组合。这种精细的方法通过适应每一层特定的计算和内存需求，确保了最佳的资源利用。

系统动态地组合多种并行类型，仔细权衡计算、内存使用和通信开销之间的关系。这种混合方法在处理复杂模型架构时特别有效，因为不同的层可能从不同的并行化策略中受益。

#### 高效的自动并行优化
Galvatron效率的核心在于其复杂的优化引擎。通过精确的成本建模，系统准确估计计算需求，预测内存使用模式，并为不同的并行化策略建立通信开销模型。这种全面的建模实现了策略选择的智能决策。

优化过程采用基于动态规划的高级搜索算法，同时考虑多个目标，包括内存效率和通信成本。系统自动适应硬件约束，同时确保最佳性能。

### (2) 通用性
Galvatron的通用性覆盖了整个Transformer架构谱系。在语言模型领域，它擅长处理从传统的BERT式编码器和GPT解码器到复杂的T5式编码器-解码器模型的各类架构。对于大型语言模型(LLMs)，系统提供专门的优化，通过谨慎管理内存和计算资源，实现了对具有万亿参数模型的高效训练。

系统的能力不仅限于语言模型，还扩展到视觉transformer架构。Galvatron可以在保持其效率的同时，适应每种架构的独特需求。在未来的版本中，Galvatron还将支持多模态架构。

### (3) 用户友好界面
尽管具有复杂的底层技术，Galvatron优先考虑用户可访问性。用户只需进行最少的代码更改即可开始训练，并得到全面文档和实用示例的支持。系统还提供与流行框架数据加载器的无缝集成，以及强大的检查点管理功能，使其成为研究和生产环境的实用选择。

## 系统架构
Galvatron的架构由三个紧密集成的核心模块组成，共同协作提供高效的分布式训练：

### (1) Galvatron 性能分析器
性能分析器作为系统的基础，对硬件能力和模型特征进行全面分析。在硬件方面，它测量设备间的通信带宽和每个设备的计算吞吐量。对于模型分析，它分析不同模型组件的计算模式、内存需求和通信需求。这些详细的分析信息为智能策略决策提供基础。

### (2) Galvatron 搜索引擎
搜索引擎是系统的大脑，利用分析数据发现最优并行化策略。它采用复杂的算法探索可能的并行配置空间，并自动为模型的每一层确定最高效的并行策略组合。

### (3) Galvatron 运行时框架
运行时框架实现执行层，将高层并行化策略转换为高效的分布式操作。该框架提供了一个健壮且灵活的执行环境，能够适应不同的硬件配置和模型架构。


### 工作流程
这三个模块无缝协作，简化分布式训练过程。用户只需提供硬件环境和Transformer模型配置。

系统自动处理分布式训练优化的所有方面，从初始分析到策略选择再到高效执行。这种架构确保了易用性和高性能，使复杂的分布式训练对更广泛的用户可访问，同时保持了高级应用所需的灵活性。

通过这种模块化设计，Galvatron在自动化和定制化之间实现了平衡，既能简单部署标准场景，又能对特殊需求进行详细控制。


<div align=center> <img src="../_static/overview.jpg" width="800" /> </div>